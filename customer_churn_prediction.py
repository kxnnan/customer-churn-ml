# -*- coding: utf-8 -*-
"""customer_churn_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ak3NXGEBmRTuH-lMImkXIPOjAp_yqLji
"""

import pandas as pd

from google.colab import files
files.upload()

df=pd.read_csv("churn.csv")
df.head()

df.shape

df.columns

df['churn'].value_counts()

import seaborn as sns
import matplotlib.pyplot as plt
sns.countplot(x='churn',data=df)
plt.title("Churn Distribution")
plt.show()

df.describe()

sns.boxplot(x='churn',y='tenure',data=df)
plt.show()

sns.boxplot(x='churn',y='monthly_charges',data=df)
plt.show()

df.info()

df['churn']=df['churn'].map({'Yes':'1','No':'2'})

df=pd.get_dummies(df,columns=['contract_type'],drop_first='True')

df.drop('customer_id',axis=1,inplace=True)

df.head()

df.info()

from sklearn.preprocessing import StandardScaler

X=df.drop('churn',axis=1)
Y=df['churn']

scaler=StandardScaler()

X_scaled=scaler.fit_transform(X)

X_scaled=pd.DataFrame(X_scaled,columns=X.columns)

X_scaled.head()

from sklearn.model_selection import train_test_split

X = df.drop('churn', axis=1)
y = df['churn']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.linear_model import LogisticRegression

model=LogisticRegression(max_iter=1000)

model.fit(X_train,y_train)

y_pred=model.predict(X_test)

y_prob=model.predict_proba(X_test)

y_prob_churn=y_prob[:,1]

print(y_test.values)
print(y_pred)

from sklearn.metrics import accuracy_score
accuracy=accuracy_score(y_test,y_pred)
print("Accuracy: ", accuracy)

from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test,y_pred)
print(cm)

from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))

from sklearn.metrics import roc_auc_score
roc=roc_auc_score(y_test,y_prob_churn)
print("ROC AUC :",roc)

from sklearn.ensemble import RandomForestClassifier

rf_model=RandomForestClassifier(
    n_estimators=100,
    random_state=42
)

rf_model.fit(X_train,y_train)

rf_pred=rf_model.predict(X_test)
rf_prob=rf_model.predict_proba(X_test)[:,1]

accuracy_score(y_test,y_pred)

accuracy_score(y_test, rf_pred)

roc_auc_score(y_test, y_prob_churn)
roc_auc_score(y_test, rf_prob)

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier(n_estimators=100,random_state=42)
cv_scores=cross_val_score(
    rf,
    X,
    y,
    cv=5,
    scoring='roc_auc'
)
print("Cross-validation ROC-AUC scores: ",cv_scores)
print("Average ROC-AUC: ",cv_scores.mean())

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5]
}

rf = RandomForestClassifier(random_state=42)

grid = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=2,
    scoring='roc_auc',
    n_jobs=-1
)

grid.fit(X, y)


print("Best Parameters:", grid.best_params_)
print("Best CV ROC-AUC:", grid.best_score_)

final_model = rf_model

from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score

final_pred = final_model.predict(X_test)
final_prob = final_model.predict_proba(X_test)[:, 1]

print("Confusion Matrix:")
print(confusion_matrix(y_test, final_pred))

print("\nClassification Report:")
print(classification_report(y_test, final_pred))

print("\nFinal ROC-AUC:")
print(roc_auc_score(y_test, final_prob))

import pandas as pd
import matplotlib.pyplot as plt

importances = final_model.feature_importances_

feature_df = pd.DataFrame({
    "Feature": X.columns,
    "Importance": importances
}).sort_values(by="Importance", ascending=False)

print(feature_df)

plt.figure()
plt.bar(feature_df["Feature"], feature_df["Importance"])
plt.xticks(rotation=90)
plt.title("Feature Importance")
plt.show()

import joblib

joblib.dump(final_model, "churn_model.pkl")

loaded_model = joblib.load("churn_model.pkl")

def predict_churn(new_data):
    prediction = final_model.predict(new_data)
    probability = final_model.predict_proba(new_data)[:, 1]
    return prediction, probability

sample = X_test.iloc[[0]]
pred, prob = predict_churn(sample)

print("Prediction:", pred)
print("Probability of churn:", prob)