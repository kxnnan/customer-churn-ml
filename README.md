
---

## âš™ï¸ Machine Learning Pipeline

### 1ï¸âƒ£ Data Preprocessing
- Handling missing values
- Encoding categorical variables
- Feature scaling (where required)

### 2ï¸âƒ£ Train-Test Split
- 80/20 split
- Ensures fair evaluation on unseen data

### 3ï¸âƒ£ Models Implemented

#### ğŸ”¹ Logistic Regression (Baseline)
- Interpretable
- Probabilistic output
- Strong baseline model

#### ğŸ”¹ Random Forest (Improved Model)
- Ensemble of decision trees
- Handles non-linearity
- Reduces overfitting
- Feature importance extraction

---

## ğŸ“ˆ Model Evaluation Metrics

The models were evaluated using:

- Accuracy
- Precision
- Recall
- F1-Score
- ROC-AUC (Primary Metric)

### Why ROC-AUC?

ROC-AUC measures the modelâ€™s ability to distinguish between churn and non-churn customers across all thresholds, making it ideal for imbalanced classification problems.

---

## ğŸ” Cross-Validation & Hyperparameter Tuning

- K-Fold Cross Validation
- GridSearchCV for optimal hyperparameters
- Tuned parameters:
  - `n_estimators`
  - `max_depth`
  - `min_samples_split`

This ensures robust and generalizable performance.

---

## ğŸŒ³ Feature Importance Analysis

Using Random Forest feature importances:

- Identified key churn drivers
- Determined most influential features
- Extracted business insights

### Key Insight Example:
Customers with lower tenure and higher monthly charges show higher churn probability.

---

## ğŸ’¾ Model Saving & Deployment Ready

The final model is serialized using:

```python
joblib.dump(model, "churn_model.pkl")
